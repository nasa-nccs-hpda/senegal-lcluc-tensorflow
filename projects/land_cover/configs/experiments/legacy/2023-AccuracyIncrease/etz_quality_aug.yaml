# --------------------------------------------------------------------------
# Configuration of the parameters for training and preprocessing
# very-high resolution dataset using deep learning techniques.
# --------------------------------------------------------------------------

experiment_name: etz-landcover-otcb-senegal-quality-tiles
experiment_type: otcb

data_dir: '/explore/nobackup/projects/3sl/development/cnn_landcover/accuracy-increase/etz-landcover-otcb-senegal-quality-tiles/tiles'
model_dir: '/explore/nobackup/projects/3sl/development/cnn_landcover/accuracy-increase/${experiment_name}-augmentation'

seed: 42
gpu_devices: 0,1,2,3
mixed_precision: False
xla: False

input_bands:
  - CoastalBlue
  - Blue
  - Green
  - Yellow
  - Red
  - RedEdge
  - NIR1
  - NIR2

output_bands:
  - Blue
  - Green
  - Red
  - NIR1

  
substract_labels: True
normalize: 1.0
rescale: None

modify_labels:
  - "x == 0": 8
  - "x == 1": 9
  - "x == 4": 7
  - "x == 3": 0
  - "x == 2": 0
  - "x == 8": 1
  - "x == 9": 2
  - "x == 7": 3

expand_dims: True
tile_size: 256
include_classes: True
augment: True

# standardization functions: local, global, mixed
# global standardization
# mixed standardization
standardization: 'local'
batch_size: 128
n_classes: 4
test_size: 0.20
learning_rate: 0.0001
max_epochs: 6000
patience: 10

#model: "tfc.networks.unet.unet_batchnorm(nclass=4, input_size=(512, 512, 4),maps=[64, 128, 256, 512, 1024])"
#model: "sm.Unet('resnet34', input_shape=(256, 256, 3), encoder_weights=None, classes=4, activation='softmax')"
model: "tfc.segmentation_unet.Attention_UNet((256,256,4), NUM_CLASSES=4, dropout_rate=0, batch_norm=True)"

loss: 'tf.keras.losses.CategoricalCrossentropy()'
#loss: 'tfc.utils.losses.focal_tversky_loss'
#loss: sm.losses.CategoricalFocalLoss
#loss: sm.losses.categorical_focal_dice_loss
#loss: sm.losses.categorical_focal_jaccard_loss

optimizer: tf.keras.optimizers.Adam

metrics:
  - 'tf.keras.metrics.CategoricalAccuracy()'
  - 'tf.keras.metrics.Recall()'
  - 'tf.keras.metrics.Precision()'
  - 'sm.metrics.iou_score'

callbacks:
  - "tf.keras.callbacks.ModelCheckpoint(save_best_only=True, mode='max', monitor='val_categorical_accuracy', filepath='${model_dir}/{epoch:02d}-{val_loss:.2f}.hdf5')"
  - "tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4)"
  - "tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=False)"
  - "tf.keras.callbacks.TerminateOnNaN()"
  - "tf.keras.callbacks.CSVLogger('${model_dir}/${experiment_name}.csv')"
  - "tf.keras.callbacks.BackupAndRestore('${model_dir}/backup')"

# window_size: 8192
window_size: 10000
pred_batch_size: 32
inference_overlap: 0.50
inference_treshold: 0.50

# Prediction location
#model_filename: /projects/kwessel4/nga-senegal-4class/dataset/model/71-0.20.hdf5 ## CAS+ETZ
#model_filename: /home/mle35/nga-senegal-4class/dataset/model_ETZ/83-0.16.hdf5
#model_filename: /projects/kwessel4/nga-senegal-4class/model/cas_wcas/51-0.20-20ts-20ts.hdf5
#inference_regex: /projects/kwessel4/allCAS/*.tif
# inference_regex: /projects/kwessel4/ETZ_data/*.tif
inference_regex_list:
  - '/explore/nobackup/people/mcarrol2/LCLUC_Senegal/ForKonrad/*_data.tif'
  - '/explore/nobackup/projects/3sl/data/VHR/ETZ/M1BS/*.tif'
  #- '/explore/nobackup/projects/3sl/data/Tappan/Tappan01_WV02_20110430_M1BS_103001000A27E100_data.tif'
  #- '/explore/nobackup/projects/ilab/projects/Ethiopia/LCLUC_Ethiopia/data/test/WV*.tif'
  #- '/explore/nobackup/projects/3sl/data/Tappan/Tappan01_WV02_20110430_M1BS_103001000A27E100_data.tif'
  #- '/explore/nobackup/projects/ilab/projects/Ethiopia/LCLUC_Ethiopia/data/test/WV*.tif'
  #- '/explore/nobackup/projects/hls/EVHR/Amhara-MS/*2015*.tif'
  #- '/explore/nobackup/projects/hls/EVHR/Amhara-MS/*2016*.tif'
  #- '/explore/nobackup/projects/hls/EVHR/Amhara-MS/*2017*.tif'
  #- '/explore/nobackup/projects/hls/EVHR/Amhara-MS/*2018*.tif'
  #- '/explore/nobackup/projects/hls/EVHR/Amhara-MS/*2019*.tif'
  #- '/explore/nobackup/projects/hls/EVHR/Amhara-MS/*2020*.tif'
  #- '/explore/nobackup/projects/hls/EVHR/Amhara-MS/*2021*.tif'
  #- '/explore/nobackup/projects/hls/EVHR/Amhara-MS/*2022*.tif'
inference_save_dir: '${model_dir}/results'
